
# Visual Based vs Lidar SLAM (Reword)

Visual SLAM relies on cameras to capture images of the environment, which are
then processed using computer vision algorithms to extract features. Laser SLAM
uses LiDAR sensors to capture 3D point clouds of the environment and estimate the
robot position and orientation.

![[Pasted image 20240801084818.png]]

Therefore decided on visual.


# Different SLAM Algorithms

![[Pasted image 20240801085448.png]]

Therefore mainly look at:
1. RTab_Map
	- https://github.com/introlab/rtabmap
	- 
1. ORB_SLAM3
	- https://github.com/UZ-SLAMLab/ORB_SLAM3
	- https://github.com/suchetanrs/ORB-SLAM3-ROS2-Docker
	- 
1. Elastic Fusion
	- https://github.com/FengyuGuo/ElasticFusionRos
	- 
Then look at:
1. RGBD-SLAM-v2
	-  https://github.com/felixendres/rgbdslam_v2
	- 
1. OKVIS
	- https://github.com/ethz-asl/okvis
	- 
1. DVO
	- https://github.com/tum-vision/dvo
	- 











# Rosbag Recording and Replaying

1. To record a Rosbag:
	1. Open a terminal and directory where rosbag should be saved and run the following code
```Shell
mkdir Rosbagrec
cd Rosbagrec
ros2 bag record /camera/camera/depth/image_rect_raw /camera/camera/depth/image_rect_raw /
```
2. To replay a Rosbag:
	1. Open rosbag directory in terminal
```Shell
cd Rosbagrec
ros2 bag play rosbag2_2024_10_31-12_20_03
```
	1. Push space to pause/play
	2. RVIZ
		2.1. Fixed Frame: camera_depth_optical_frame
	    2.2. Depthcloud: /camera/camera/depth/image_rect_raw
	3. rosbag2_2024_10_31-12_15_06
	4. rosbag2_2024_10_31-12_03_43
	5. rosbag2_2024_10_31-12_20_03





# Mapping Test Instructions

1. Start Hotspot from PC
2. Connect drone battery and wait for dronePi to appear on mobile hotspot
3. login to pi using ssh (3 terminals)
```
ssh dronepi@192.168.137.50
ssh khadas@192.168.137.166 (VIM)
```
3. start nodes for pi to connect to FC
```Shell
sudo MicroXRCEAgent serial --dev /dev/serial0 -b 921600
sudo MicroXRCEAgent serial --dev /dev/ttyS4 -b 921600 (VIM)
```
4. Now Check ros2 topic list
5. Start Camera node and make sure topics are present:
	1. realsense camera node (Depth)
```
ros2 run realsense2_camera realsense2_camera_node --ros-args -p enable_color:=false -p spatial_filter.enable:=true -p temporal_filter.enable:=true
```
	2. OAK-D (RGBD-0.6Hz) (/stereo/points or /stereo/converted_depth and /color/image)
```Shell
ros2 launch depthai_examples stereo_inertial_node.launch.py subpixel:=False rectify:=False enableRviz:=False
```
	3. OAK-D (Depth-1.3Hz;14.5Hz) (/stereo/points or /stereo/converted_depth)
```Shell
ros2 launch depthai_examples stereo_inertial_node.launch.py subpixel:=False rectify:=False enableRviz:=False
```

6. for vim only, you have to manually mount the sd card
```Shell
sudo mount /dev/mmcblk1p1 /home/khadas/SDCardMount
cd SDCardMount/Rosbag20241129
```
Note. use 'lsblk' to see mounted drives and details

7. start rosbag recording(make sure of topics):
```Shell
mkdir Rosbagrec
cd Rosbagrec
ros2 bag record -a


VIM:
cd /media/khadas/1604-2516/15_11_2024
ros2 bag record /clicked_point /color/camera_info /color/image /color/image/compressed /color/image/compressedDepth /color/image/theora  /events/read_split /events/write_split /goal_pose /image/compressed /image/compressedDepth /image/theora /parameter_events /robot_description /rosout /stereo/camera_info /stereo/converted_depth /stereo/depth /stereo/depth/compressed /stereo/depth/compressedDepth /stereo/depth/theora /stereo/points /tf /tf_static /fmu/out/failsafe_flags /fmu/out/position_setpoint_triplet /fmu/out/sensor_combined /fmu/out/timesync_status /fmu/out/vehicle_attitude /fmu/out/vehicle_control_mode /fmu/out/vehicle_local_position /fmu/out/vehicle_odometry /fmu/out/vehicle_status


VIM:
cd /media/khadas/1604-2516/15_11_2024
ros2 bag record /clicked_point /color/camera_info /color/image /robot_description /rosout /stereo/camera_info /stereo/converted_depth /stereo/depth /stereo/points /tf /tf_static /fmu/out/position_setpoint_triplet /fmu/out/sensor_combined /fmu/out/vehicle_attitude /fmu/out/vehicle_local_position /fmu/out/vehicle_odometry
```
7. Disconnect monitor
8. transport drone to safe starting point (This might mess with kalman filter a bit?????)
9. take of and start mapping. 
10. connect monitor
11. transfer rosbag and delete on pi
12. repeat
13. in end, in 2 terminals type "exit" and in last one type "sudo poweroff", remove battery




# Test Results 5 Nov 2024 (IR, OAK, Position)

1. Test 1(IR): rosbag2_2023_11_21-23_04_01/rosbag2_2023_11_21-23_04_01_0.db3
```Shell
cd Rosbagrec_2024-11-05
ros2 bag play rosbag2_2023_11_21-23_04_01
```
2 front
3 back
2 right
1 back
1 left
2 front + 1 left


2. Test 2(IR): rosbag2_2023_11_21-23_11_33/rosbag2_2023_11_21-23_11_33_0.db3
```Shell
cd Rosbagrec_2024-11-05
ros2 bag play rosbag2_2023_11_21-23_11_33
```
3-4 front
rotate 90 ccw
rotate 90 ccw
3-4 front
rotate 90 ccw
rotate 90 ccw


3. Test 3(IR): rosbag2_2023_11_21-23_20_46/rosbag2_2023_11_21-23_20_46_0.db3 (PX4 topics only) 
```Shell
cd Rosbagrec_2024-11-05
ros2 bag play rosbag2_2023_11_21-23_20_46
```
ros2 bag record /fmu/out/failsafe_flags /fmu/out/position_setpoint_triplet /fmu/out/sensor_combined /fmu/out/timesync_status /fmu/out/vehicle_attitude /fmu/out/vehicle_control_mode /fmu/out/vehicle_local_position /fmu/out/vehicle_odometry /fmu/out/vehicle_status
- move from marker to marker. See video 5 Nov 2024 (13:51_Duration:5:01)


4. Test 4(OAK): rosbag2_2023_11_21-23_02_12/rosbag2_2023_11_21-23_02_12_0.db3
	FAIL


5. Test 5(OAK-RGBD): rosbag2_2023_11_21-23_02_16/rosbag2_2023_11_21-23_02_16_0.db3
2front
rotate180
2front
rotate180


6. Test 6(OAK-RGBD): rosbag2_2023_11_21-23_08_05
2front
180
2front
bit random
random stop, battery dead


# Test Results 14 Nov 2024 (OAK Live on VIM, EKF2 reinitialize)

Tests:
1. General test after doing changes to frame and mounting oak-d. Also, feet extension so that oak cable doesn't hit floor
	1. Test successful, position hold still works and when dropping drone from a distance in air, feet dont break
2. Oak-D live footage
	1. Took Single video
3. Reinitialize EKF (on ground, after takeoff in hover, after moving a bit) (Not Done)




# Test Results 29 Nov 2024 (OAK Live (with L adapter) on VIM, OF displaced 25mm to back, magnetometer off and gps ekf2 disabled)

1. Test1:
	1. 3F 2L 1F 1R 3B 1R 1B 360 rot (movements with rotation, but cant remember. maybe 360 after first 3F)






# My First Map: Transforming Pointcloud according to position and orientation (Not Confirmed to Work)

Need:
1. Apply transfrom from point cloud reference frame to quad reference frame:
	1. Transforms within Camera --TICK 
	2. figure out in what frame of reference point cloud is published
	3. reverse transform and figure out transform of camera relative to drone
	4. find one big transform from point cloud reference frame to quad.
2. Extract 3d point cloud from ros2 topic
	1. 
3. Apply quad rotation, relative to starting orientation
	1. Take current orientation
	2. find rotation matrix, rotating quad to original orientation
4. Apply Quad Translation
	1. Take current position
	2. find translation , translating quad to original position
5. Save point cloud data to a single file and incrementally add
6. display point cloud

## 1. Apply transfrom from point cloud reference frame to quad reference frame:#

### 1.1. All Published Static Transforms
From 'ros2 topic echo /tf_static'

```Shell
transforms:
- header:
    stamp:
      sec: 1732887486
      nanosec: 855881877
    frame_id: oak-d-base-frame
  child_frame_id: oak-d_frame
  transform:
    translation:
      x: 0.0
      y: 0.0
      z: 0.0
    rotation:
      x: 0.0
      y: 0.0
      z: 0.0
      w: 1.0
- header:
    stamp:
      sec: 1732887486
      nanosec: 855881877
    frame_id: oak-d_frame
  child_frame_id: oak_imu_frame
  transform:
    translation:
      x: 0.0
      y: -0.015
      z: -0.013662
    rotation:
      x: 0.0
      y: 0.7071067811865475
      z: 0.0
      w: 0.7071067811865476
- header:
    stamp:
      sec: 1732887486
      nanosec: 855881877
    frame_id: oak-d_frame
  child_frame_id: oak_left_camera_frame
  transform:
    translation:
      x: 0.0
      y: 0.0375
      z: 0.0
    rotation:
      x: 0.0
      y: 0.0
      z: 0.0
      w: 1.0
- header:
    stamp:
      sec: 1732887486
      nanosec: 855881877
    frame_id: oak_left_camera_frame
  child_frame_id: oak_left_camera_optical_frame
  transform:
    translation:
      x: 0.0
      y: 0.0
      z: 0.0
    rotation:
      x: 0.5
      y: -0.4999999999999999
      z: 0.5
      w: -0.5000000000000001
- header:
    stamp:
      sec: 1732887486
      nanosec: 855881877
    frame_id: oak-d_frame
  child_frame_id: oak_model_origin
  transform:
    translation:
      x: 0.0
      y: 0.0
      z: 0.0
    rotation:
      x: 0.4999999999966269
      y: 0.5000018366025517
      z: 0.4999999999966269
      w: 0.49999816339744835
- header:
    stamp:
      sec: 1732887486
      nanosec: 855881877
    frame_id: oak-d_frame
  child_frame_id: oak_rgb_camera_frame
  transform:
    translation:
      x: 0.0
      y: 0.0
      z: 0.0
    rotation:
      x: 0.0
      y: 0.0
      z: 0.0
      w: 1.0
- header:
    stamp:
      sec: 1732887486
      nanosec: 855881877
    frame_id: oak_rgb_camera_frame
  child_frame_id: oak_rgb_camera_optical_frame
  transform:
    translation:
      x: 0.0
      y: 0.0
      z: 0.0
    rotation:
      x: 0.5
      y: -0.4999999999999999
      z: 0.5
      w: -0.5000000000000001
- header:
    stamp:
      sec: 1732887486
      nanosec: 855881877
    frame_id: oak-d_frame
  child_frame_id: oak_right_camera_frame
  transform:
    translation:
      x: 0.0
      y: -0.0375
      z: 0.0
    rotation:
      x: 0.0
      y: 0.0
      z: 0.0
      w: 1.0
- header:
    stamp:
      sec: 1732887486
      nanosec: 855881877
    frame_id: oak_right_camera_frame
  child_frame_id: oak_right_camera_optical_frame
  transform:
    translation:
      x: 0.0
      y: 0.0
      z: 0.0
    rotation:
      x: 0.5
      y: -0.4999999999999999
      z: 0.5
      w: -0.5000000000000001
---

```



### 1.2. Figure out in what frame of reference point cloud is published

From 'ros2 topic echo /stereo/points --qos-reliability best_effort', you can find frame_id:
Example sample from this command:
```Shell
---
A message was lost!!!
	total count change:2
	total count: 31---
header:
  stamp:
    sec: 1732887758
    nanosec: 485706934
  frame_id: oak_rgb_camera_optical_frame
height: 720
width: 1280
fields:
- name: x
  offset: 0
  datatype: 7
  count: 1
- name: y
  offset: 4
  datatype: 7
  count: 1
- name: z
  offset: 8
  datatype: 7
  count: 1
- name: rgb
  offset: 16
  datatype: 7
  count: 1
is_bigendian: false
point_step: 32
row_step: 40960
data:
- 157
- 189
- 121
- 192
- 191
- 81
- 14
- 192
- 52
- 51
- 151
- 64
- 0
- 0
- 0
- 0
- 214
- 199
- 197
- 0
- 0
- 0
- 0
- 0
- 0
- 0
- 0
- 0
- 0
- 0
- 0
- 0
- 76
- 88
- 121
- 192
- 191
- 81
- 14
- 192
- 52
- 51
- 151
- 64
- 0
- 0
- 0
- 0
- 220
- 205
- 203
- 0
- 0
- 0
- 0
- 0
- 0
- 0
- 0
- 0
- 0
- 0
- 0
- 0
- 253
- 242
- 120
- 192
- 191
- 81
- 14
- 192
- 52
- 51
- 151
- 64
- 0
- 0
- 0
- 0
- 226
- 211
- 209
- 0
- 0
- 0
- 0
- 0
- 0
- 0
- 0
- 0
- 0
- 0
- 0
- 0
- 172
- 141
- 120
- 192
- 191
- 81
- 14
- 192
- 52
- 51
- 151
- 64
- 0
- 0
- 0
- 0
- 231
- 215
- 213
- 0
- 0
- 0
- 0
- 0
- 0
- 0
- 0
- 0
- 0
- 0
- 0
- 0
- '...'
is_dense: false
---

```

Transformation from oak_rgb_camera_optical_frame to oak-d-base-frame:
```Shell
- **Translation:** (0.0, 0.0, 0.0)
- **Rotation (quaternion):** (0.5, -0.5, 0.5, -0.5
```



### 1.3. reverse transform and figure out transform of camera relative to drone

The transformation from the **`oak-d-base-frame`** to the quadcopter's **COG** in PX4 NED is (Assuming camera is situated 20cm forward and 5cm down, facing forward)

- **Translation:** [−0.2,0,0.05][-0.2, 0, 0.05][−0.2,0,0.05]
- **Rotation (quaternion):** [0,0,0.7071,0.7071][0, 0, 0.7071, 0.7071][0,0,0.7071,0.7071]

### 1.4. find one big transform from point cloud reference frame to quad.

- **Rotate the Point Cloud:**
    - Use the quaternion [0.0,−0.7071,0.0,−0.7071][0.0, -0.7071, 0.0, -0.7071][0.0,−0.7071,0.0,−0.7071] to rotate each point in the point cloud from the **`oak_rgb_camera_optical_frame`** to align it with the quadcopter’s orientation.
    - This can be done using a library like `tf2` in ROS, or directly in Python using `scipy` or another quaternion-handling library.
- **Translate the Point Cloud:**
    - Add the translation vector [0.05,0.2,0.0][0.05, 0.2, 0.0][0.05,0.2,0.0] to each point in the point cloud.

![[Screenshot from 2024-12-04 08-31-29.png]]



## 2. Extract 3d point cloud from ros2 topic:




## 3. Apply quad rotation, relative to starting orientation

1. Take current orientation
2. find rotation matrix, rotating quad to original orientation


## 4. Apply Quad Translation

1. Take current position
2. find translation , translating quad to original position

# 5. Save point cloud data to a single file and incrementally add







